//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21554848
// Cuda compilation tools, release 8.0, V8.0.61
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_35
.address_size 64

	// .weak	cudaMalloc
.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.visible .global .align 8 .b8 d_cxt[80];
.global .align 1 .b8 $str5[11] = {115, 108, 111, 119, 32, 114, 101, 97, 100, 10, 0};
.global .align 1 .b8 $str6[12] = {115, 108, 111, 119, 32, 119, 114, 105, 116, 101, 10, 0};

.weak .func  (.param .b32 func_retval0) cudaMalloc(
	.param .b64 cudaMalloc_param_0,
	.param .b64 cudaMalloc_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaFuncGetAttributes
.weak .func  (.param .b32 func_retval0) cudaFuncGetAttributes(
	.param .b64 cudaFuncGetAttributes_param_0,
	.param .b64 cudaFuncGetAttributes_param_1
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaDeviceGetAttribute
.weak .func  (.param .b32 func_retval0) cudaDeviceGetAttribute(
	.param .b64 cudaDeviceGetAttribute_param_0,
	.param .b32 cudaDeviceGetAttribute_param_1,
	.param .b32 cudaDeviceGetAttribute_param_2
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaGetDevice
.weak .func  (.param .b32 func_retval0) cudaGetDevice(
	.param .b64 cudaGetDevice_param_0
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessor
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessor(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessor_param_3
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .weak	cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags
.weak .func  (.param .b32 func_retval0) cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_0,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_1,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_2,
	.param .b64 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_3,
	.param .b32 cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags_param_4
)
{
	.reg .b32 	%r<2>;


	mov.u32 	%r1, 30;
	st.param.b32	[func_retval0+0], %r1;
	ret;
}

	// .globl	shfl_address
.visible .func  (.param .b64 func_retval0) shfl_address(
	.param .b64 shfl_address_param_0,
	.param .b32 shfl_address_param_1
)
{
	.reg .b32 	%r<11>;
	.reg .b64 	%rd<2>;


	ld.param.u32 	%r3, [shfl_address_param_1];
	ld.param.v2.u32 	{%r9, %r10}, [shfl_address_param_0];
	mov.u32 	%r8, 31;
	// inline asm
	shfl.idx.b32 %r1, %r9, %r3, %r8;
	// inline asm
	// inline asm
	shfl.idx.b32 %r5, %r10, %r3, %r8;
	// inline asm
	mov.b64	%rd1, {%r1, %r5};
	st.param.b64	[func_retval0+0], %rd1;
	ret;
}

	// .globl	cpuptr_init
.visible .func  (.param .b64 func_retval0) cpuptr_init(
	.param .b64 cpuptr_init_param_0
)
{
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [cpuptr_init_param_0];
	or.b64  	%rd2, %rd1, -9223372036854775808;
	st.param.b64	[func_retval0+0], %rd2;
	ret;
}

	// .globl	cpuptr_link
.visible .func  (.param .b64 func_retval0) cpuptr_link(
	.param .b64 cpuptr_link_param_0
)
{
	.reg .pred 	%p<21>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<69>;
	.reg .b64 	%rd<94>;


	ld.param.u64 	%rd93, [cpuptr_link_param_0];
	shr.u64 	%rd31, %rd93, 63;
	cvt.u32.u64	%r7, %rd31;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	.reg .pred 	%p2; 
	setp.ne.u32 	%p1, %r7, 0; 
	vote.any.pred 	%p2, %p1; 
	selp.s32 	%r6, 1, 0, %p2; 
	}
	// inline asm
	setp.eq.s32	%p2, %r6, 0;
	@%p2 bra 	BB8_34;

	mov.u64 	%rd90, 0;
	setp.gt.s64	%p3, %rd93, -1;
	@%p3 bra 	BB8_3;

	and.b64  	%rd90, %rd93, 9223372036854771712;

BB8_3:
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r7, 0; 
	vote.ballot.b32 	%r8, %p1; 
	}
	// inline asm
	neg.s32 	%r10, %r8;
	and.b32  	%r11, %r8, %r10;
	clz.b32 	%r68, %r11;
	setp.eq.s32	%p4, %r68, 32;
	@%p4 bra 	BB8_34;

	cvt.u16.u64	%rs7, %rd31;

BB8_5:
	mov.u32 	%r2, %r68;
	mov.u32 	%r19, 31;
	sub.s32 	%r3, %r19, %r2;
	mov.b64	{%r13, %r17}, %rd90;
	// inline asm
	shfl.idx.b32 %r12, %r13, %r3, %r19;
	// inline asm
	// inline asm
	shfl.idx.b32 %r16, %r17, %r3, %r19;
	// inline asm
	mov.b64	%rd4, {%r12, %r16};
	setp.eq.s64	%p5, %rd4, %rd90;
	and.b16  	%rs4, %rs7, 255;
	setp.ne.s16	%p6, %rs4, 0;
	and.pred  	%p1, %p6, %p5;
	selp.u32	%r21, 1, 0, %p1;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r21, 0; 
	vote.ballot.b32 	%r20, %p1; 
	}
	// inline asm
	popc.b32 	%r4, %r20;
	// inline asm
	mov.u32 %r22, %laneid;
	// inline asm
	setp.ne.s32	%p7, %r22, %r3;
	@%p7 bra 	BB8_30;

	bfe.u64 	%rd5, %rd4, 12, 51;
	ld.global.s32 	%rd6, [d_cxt+32];
	or.b64  	%rd36, %rd5, %rd6;
	and.b64  	%rd37, %rd36, -4294967296;
	setp.eq.s64	%p8, %rd37, 0;
	@%p8 bra 	BB8_8;
	bra.uni 	BB8_7;

BB8_8:
	cvt.u32.u64	%r23, %rd6;
	cvt.u32.u64	%r24, %rd5;
	rem.u32 	%r25, %r24, %r23;
	cvt.u64.u32	%rd91, %r25;
	bra.uni 	BB8_9;

BB8_7:
	rem.u64 	%rd91, %rd5, %rd6;

BB8_9:
	and.b64  	%rd10, %rd91, 4294967295;
	ld.global.u64 	%rd11, [d_cxt+48];
	mul.lo.s64 	%rd38, %rd10, 24;
	add.s64 	%rd39, %rd11, %rd38;
	add.s64 	%rd12, %rd39, 12;

BB8_10:
	atom.exch.b32 	%r26, [%rd12], 1;
	setp.ne.s32	%p9, %r26, 0;
	@%p9 bra 	BB8_10;

	add.s64 	%rd13, %rd39, 16;
	ld.u32 	%r27, [%rd39+16];
	setp.eq.s32	%p10, %r27, 0;
	@%p10 bra 	BB8_24;
	bra.uni 	BB8_12;

BB8_24:
	ld.global.u64 	%rd73, [d_cxt+40];
	shl.b64 	%rd74, %rd10, 12;
	add.s64 	%rd92, %rd73, %rd74;
	mov.u64 	%rd75, d_cxt;
	ld.global.u64 	%rd76, [d_cxt];
	add.s64 	%rd77, %rd76, 4294967295;
	cvt.u32.u64	%r46, %rd77;
	add.s64 	%rd78, %rd75, 16;
	atom.global.inc.u32 	%r47, [%rd78], %r46;
	cvt.s64.s32	%rd22, %r47;

BB8_25:
	ld.global.u64 	%rd79, [d_cxt+24];
	shl.b64 	%rd80, %rd22, 2;
	add.s64 	%rd81, %rd79, %rd80;
	atom.exch.b32 	%r48, [%rd81], 1;
	setp.ne.s32	%p17, %r48, 0;
	@%p17 bra 	BB8_25;

	ld.global.u64 	%rd82, [d_cxt+8];
	mul.lo.s64 	%rd83, %rd22, 24;
	add.s64 	%rd84, %rd82, %rd83;
	st.u64 	[%rd84], %rd4;
	st.u64 	[%rd84+8], %rd92;
	add.s64 	%rd23, %rd84, 16;
	mov.u32 	%r49, 4096;
	st.u32 	[%rd84+16], %r49;
	membar.sys;
	mov.u32 	%r50, 1;
	st.volatile.u32 	[%rd84+20], %r50;
	membar.sys;

BB8_27:
	ld.volatile.u32 	%r51, [%rd23+4];
	setp.ne.s32	%p18, %r51, 0;
	@%p18 bra 	BB8_27;

	ld.global.u64 	%rd85, [d_cxt+24];
	add.s64 	%rd87, %rd85, %rd80;
	atom.exch.b32 	%r52, [%rd87], 0;
	st.u64 	[%rd13+-16], %rd4;
	st.u32 	[%rd13+-8], %r4;
	st.u32 	[%rd13], %r50;
	bra.uni 	BB8_29;

BB8_12:
	ld.u64 	%rd14, [%rd13+-16];
	setp.eq.s64	%p11, %rd14, %rd4;
	@%p11 bra 	BB8_23;
	bra.uni 	BB8_13;

BB8_23:
	ld.global.u64 	%rd71, [d_cxt+40];
	ld.u32 	%r44, [%rd13+-8];
	add.s32 	%r45, %r44, %r4;
	st.u32 	[%rd13+-8], %r45;
	shl.b64 	%rd72, %rd10, 12;
	add.s64 	%rd92, %rd71, %rd72;
	bra.uni 	BB8_29;

BB8_13:
	ld.u32 	%r28, [%rd13+-8];
	mov.u64 	%rd92, 0;
	setp.ne.s32	%p12, %r28, 0;
	@%p12 bra 	BB8_29;

	ld.global.u64 	%rd43, [d_cxt+40];
	shl.b64 	%rd44, %rd10, 12;
	add.s64 	%rd92, %rd43, %rd44;
	mov.u64 	%rd45, d_cxt;
	ld.global.u64 	%rd46, [d_cxt];
	add.s64 	%rd47, %rd46, 4294967295;
	cvt.u32.u64	%r29, %rd47;
	add.s64 	%rd48, %rd45, 16;
	atom.global.inc.u32 	%r30, [%rd48], %r29;
	cvt.s64.s32	%rd16, %r30;

BB8_15:
	ld.global.u64 	%rd49, [d_cxt+24];
	shl.b64 	%rd50, %rd16, 2;
	add.s64 	%rd51, %rd49, %rd50;
	atom.exch.b32 	%r31, [%rd51], 1;
	setp.ne.s32	%p13, %r31, 0;
	@%p13 bra 	BB8_15;

	ld.global.u64 	%rd52, [d_cxt+8];
	mul.lo.s64 	%rd53, %rd16, 24;
	add.s64 	%rd54, %rd52, %rd53;
	st.u64 	[%rd54], %rd14;
	st.u64 	[%rd54+8], %rd92;
	add.s64 	%rd17, %rd54, 16;
	mov.u32 	%r32, 4096;
	st.u32 	[%rd54+16], %r32;
	membar.sys;
	mov.u32 	%r33, 2;
	st.volatile.u32 	[%rd54+20], %r33;
	membar.sys;

BB8_17:
	ld.volatile.u32 	%r34, [%rd17+4];
	setp.ne.s32	%p14, %r34, 0;
	@%p14 bra 	BB8_17;

	ld.global.u64 	%rd55, [d_cxt+24];
	add.s64 	%rd57, %rd55, %rd50;
	atom.exch.b32 	%r35, [%rd57], 0;
	ld.global.u64 	%rd59, [d_cxt];
	add.s64 	%rd60, %rd59, 4294967295;
	cvt.u32.u64	%r36, %rd60;
	atom.global.inc.u32 	%r37, [%rd48], %r36;
	cvt.s64.s32	%rd18, %r37;

BB8_19:
	ld.global.u64 	%rd62, [d_cxt+24];
	shl.b64 	%rd63, %rd18, 2;
	add.s64 	%rd64, %rd62, %rd63;
	atom.exch.b32 	%r38, [%rd64], 1;
	setp.ne.s32	%p15, %r38, 0;
	@%p15 bra 	BB8_19;

	ld.global.u64 	%rd65, [d_cxt+8];
	mul.lo.s64 	%rd66, %rd18, 24;
	add.s64 	%rd67, %rd65, %rd66;
	st.u64 	[%rd67], %rd4;
	st.u64 	[%rd67+8], %rd92;
	add.s64 	%rd19, %rd67, 16;
	st.u32 	[%rd67+16], %r32;
	membar.sys;
	mov.u32 	%r40, 1;
	st.volatile.u32 	[%rd67+20], %r40;
	membar.sys;

BB8_21:
	ld.volatile.u32 	%r41, [%rd19+4];
	setp.ne.s32	%p16, %r41, 0;
	@%p16 bra 	BB8_21;

	ld.global.u64 	%rd68, [d_cxt+24];
	add.s64 	%rd70, %rd68, %rd63;
	atom.exch.b32 	%r42, [%rd70], 0;
	st.u64 	[%rd13+-16], %rd4;
	st.u32 	[%rd13], %r40;

BB8_29:
	atom.exch.b32 	%r54, [%rd12], 0;

BB8_30:
	mov.b64	{%r56, %r60}, %rd92;
	// inline asm
	shfl.idx.b32 %r55, %r56, %r3, %r19;
	// inline asm
	// inline asm
	shfl.idx.b32 %r59, %r60, %r3, %r19;
	// inline asm
	mov.b64	%rd26, {%r55, %r59};
	@!%p1 bra 	BB8_33;
	bra.uni 	BB8_31;

BB8_31:
	setp.eq.s64	%p19, %rd26, 0;
	mov.u16 	%rs7, 0;
	@%p19 bra 	BB8_33;

	and.b64  	%rd88, %rd93, 4095;
	and.b64  	%rd89, %rd26, 9223372036854775807;
	or.b64  	%rd93, %rd89, %rd88;

BB8_33:
	cvt.u32.u16	%r65, %rs7;
	and.b32  	%r64, %r65, 255;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r64, 0; 
	vote.ballot.b32 	%r63, %p1; 
	}
	// inline asm
	neg.s32 	%r66, %r63;
	and.b32  	%r67, %r63, %r66;
	clz.b32 	%r68, %r67;
	setp.ne.s32	%p20, %r68, 32;
	@%p20 bra 	BB8_5;

BB8_34:
	st.param.b64	[func_retval0+0], %rd93;
	ret;
}

	// .globl	cpuptr_unlink
.visible .func  (.param .b64 func_retval0) cpuptr_unlink(
	.param .b64 cpuptr_unlink_param_0
)
{
	.reg .b64 	%rd<3>;


	ld.param.u64 	%rd1, [cpuptr_unlink_param_0];
	or.b64  	%rd2, %rd1, -9223372036854775808;
	st.param.b64	[func_retval0+0], %rd2;
	ret;
}

	// .globl	cpuptr_read_int
.visible .func  (.param .b64 func_retval0) cpuptr_read_int(
	.param .b64 cpuptr_read_int_param_0,
	.param .b64 cpuptr_read_int_param_1
)
{
	.reg .pred 	%p<24>;
	.reg .b16 	%rs<8>;
	.reg .b32 	%r<78>;
	.reg .b64 	%rd<114>;


	ld.param.u64 	%rd113, [cpuptr_read_int_param_0];
	ld.param.u64 	%rd34, [cpuptr_read_int_param_1];
	shr.u64 	%rd35, %rd113, 63;
	cvt.u32.u64	%r7, %rd35;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	.reg .pred 	%p2; 
	setp.ne.u32 	%p1, %r7, 0; 
	vote.any.pred 	%p2, %p1; 
	selp.s32 	%r6, 1, 0, %p2; 
	}
	// inline asm
	setp.eq.s32	%p2, %r6, 0;
	@%p2 bra 	BB10_34;

	mov.u64 	%rd110, 0;
	setp.gt.s64	%p3, %rd113, -1;
	@%p3 bra 	BB10_3;

	and.b64  	%rd110, %rd113, 9223372036854771712;

BB10_3:
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r7, 0; 
	vote.ballot.b32 	%r8, %p1; 
	}
	// inline asm
	neg.s32 	%r10, %r8;
	and.b32  	%r11, %r8, %r10;
	clz.b32 	%r77, %r11;
	setp.eq.s32	%p4, %r77, 32;
	@%p4 bra 	BB10_34;

	cvt.u16.u64	%rs7, %rd35;

BB10_5:
	mov.u32 	%r2, %r77;
	mov.u32 	%r19, 31;
	sub.s32 	%r3, %r19, %r2;
	mov.b64	{%r13, %r17}, %rd110;
	// inline asm
	shfl.idx.b32 %r12, %r13, %r3, %r19;
	// inline asm
	// inline asm
	shfl.idx.b32 %r16, %r17, %r3, %r19;
	// inline asm
	mov.b64	%rd4, {%r12, %r16};
	setp.eq.s64	%p5, %rd4, %rd110;
	and.b16  	%rs4, %rs7, 255;
	setp.ne.s16	%p6, %rs4, 0;
	and.pred  	%p1, %p6, %p5;
	selp.u32	%r21, 1, 0, %p1;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r21, 0; 
	vote.ballot.b32 	%r20, %p1; 
	}
	// inline asm
	popc.b32 	%r4, %r20;
	// inline asm
	mov.u32 %r22, %laneid;
	// inline asm
	setp.ne.s32	%p7, %r22, %r3;
	@%p7 bra 	BB10_30;

	bfe.u64 	%rd5, %rd4, 12, 51;
	ld.global.s32 	%rd6, [d_cxt+32];
	or.b64  	%rd40, %rd5, %rd6;
	and.b64  	%rd41, %rd40, -4294967296;
	setp.eq.s64	%p8, %rd41, 0;
	@%p8 bra 	BB10_8;
	bra.uni 	BB10_7;

BB10_8:
	cvt.u32.u64	%r23, %rd6;
	cvt.u32.u64	%r24, %rd5;
	rem.u32 	%r25, %r24, %r23;
	cvt.u64.u32	%rd111, %r25;
	bra.uni 	BB10_9;

BB10_7:
	rem.u64 	%rd111, %rd5, %rd6;

BB10_9:
	and.b64  	%rd10, %rd111, 4294967295;
	ld.global.u64 	%rd11, [d_cxt+48];
	mul.lo.s64 	%rd42, %rd10, 24;
	add.s64 	%rd43, %rd11, %rd42;
	add.s64 	%rd12, %rd43, 12;

BB10_10:
	atom.exch.b32 	%r26, [%rd12], 1;
	setp.ne.s32	%p9, %r26, 0;
	@%p9 bra 	BB10_10;

	add.s64 	%rd13, %rd43, 16;
	ld.u32 	%r27, [%rd43+16];
	setp.eq.s32	%p10, %r27, 0;
	@%p10 bra 	BB10_24;
	bra.uni 	BB10_12;

BB10_24:
	ld.global.u64 	%rd77, [d_cxt+40];
	shl.b64 	%rd78, %rd10, 12;
	add.s64 	%rd112, %rd77, %rd78;
	mov.u64 	%rd79, d_cxt;
	ld.global.u64 	%rd80, [d_cxt];
	add.s64 	%rd81, %rd80, 4294967295;
	cvt.u32.u64	%r46, %rd81;
	add.s64 	%rd82, %rd79, 16;
	atom.global.inc.u32 	%r47, [%rd82], %r46;
	cvt.s64.s32	%rd22, %r47;

BB10_25:
	ld.global.u64 	%rd83, [d_cxt+24];
	shl.b64 	%rd84, %rd22, 2;
	add.s64 	%rd85, %rd83, %rd84;
	atom.exch.b32 	%r48, [%rd85], 1;
	setp.ne.s32	%p17, %r48, 0;
	@%p17 bra 	BB10_25;

	ld.global.u64 	%rd86, [d_cxt+8];
	mul.lo.s64 	%rd87, %rd22, 24;
	add.s64 	%rd88, %rd86, %rd87;
	st.u64 	[%rd88], %rd4;
	st.u64 	[%rd88+8], %rd112;
	add.s64 	%rd23, %rd88, 16;
	mov.u32 	%r49, 4096;
	st.u32 	[%rd88+16], %r49;
	membar.sys;
	mov.u32 	%r50, 1;
	st.volatile.u32 	[%rd88+20], %r50;
	membar.sys;

BB10_27:
	ld.volatile.u32 	%r51, [%rd23+4];
	setp.ne.s32	%p18, %r51, 0;
	@%p18 bra 	BB10_27;

	ld.global.u64 	%rd89, [d_cxt+24];
	add.s64 	%rd91, %rd89, %rd84;
	atom.exch.b32 	%r52, [%rd91], 0;
	st.u64 	[%rd13+-16], %rd4;
	st.u32 	[%rd13+-8], %r4;
	st.u32 	[%rd13], %r50;
	bra.uni 	BB10_29;

BB10_12:
	ld.u64 	%rd14, [%rd13+-16];
	setp.eq.s64	%p11, %rd14, %rd4;
	@%p11 bra 	BB10_23;
	bra.uni 	BB10_13;

BB10_23:
	ld.global.u64 	%rd75, [d_cxt+40];
	ld.u32 	%r44, [%rd13+-8];
	add.s32 	%r45, %r44, %r4;
	st.u32 	[%rd13+-8], %r45;
	shl.b64 	%rd76, %rd10, 12;
	add.s64 	%rd112, %rd75, %rd76;
	bra.uni 	BB10_29;

BB10_13:
	ld.u32 	%r28, [%rd13+-8];
	mov.u64 	%rd112, 0;
	setp.ne.s32	%p12, %r28, 0;
	@%p12 bra 	BB10_29;

	ld.global.u64 	%rd47, [d_cxt+40];
	shl.b64 	%rd48, %rd10, 12;
	add.s64 	%rd112, %rd47, %rd48;
	mov.u64 	%rd49, d_cxt;
	ld.global.u64 	%rd50, [d_cxt];
	add.s64 	%rd51, %rd50, 4294967295;
	cvt.u32.u64	%r29, %rd51;
	add.s64 	%rd52, %rd49, 16;
	atom.global.inc.u32 	%r30, [%rd52], %r29;
	cvt.s64.s32	%rd16, %r30;

BB10_15:
	ld.global.u64 	%rd53, [d_cxt+24];
	shl.b64 	%rd54, %rd16, 2;
	add.s64 	%rd55, %rd53, %rd54;
	atom.exch.b32 	%r31, [%rd55], 1;
	setp.ne.s32	%p13, %r31, 0;
	@%p13 bra 	BB10_15;

	ld.global.u64 	%rd56, [d_cxt+8];
	mul.lo.s64 	%rd57, %rd16, 24;
	add.s64 	%rd58, %rd56, %rd57;
	st.u64 	[%rd58], %rd14;
	st.u64 	[%rd58+8], %rd112;
	add.s64 	%rd17, %rd58, 16;
	mov.u32 	%r32, 4096;
	st.u32 	[%rd58+16], %r32;
	membar.sys;
	mov.u32 	%r33, 2;
	st.volatile.u32 	[%rd58+20], %r33;
	membar.sys;

BB10_17:
	ld.volatile.u32 	%r34, [%rd17+4];
	setp.ne.s32	%p14, %r34, 0;
	@%p14 bra 	BB10_17;

	ld.global.u64 	%rd59, [d_cxt+24];
	add.s64 	%rd61, %rd59, %rd54;
	atom.exch.b32 	%r35, [%rd61], 0;
	ld.global.u64 	%rd63, [d_cxt];
	add.s64 	%rd64, %rd63, 4294967295;
	cvt.u32.u64	%r36, %rd64;
	atom.global.inc.u32 	%r37, [%rd52], %r36;
	cvt.s64.s32	%rd18, %r37;

BB10_19:
	ld.global.u64 	%rd66, [d_cxt+24];
	shl.b64 	%rd67, %rd18, 2;
	add.s64 	%rd68, %rd66, %rd67;
	atom.exch.b32 	%r38, [%rd68], 1;
	setp.ne.s32	%p15, %r38, 0;
	@%p15 bra 	BB10_19;

	ld.global.u64 	%rd69, [d_cxt+8];
	mul.lo.s64 	%rd70, %rd18, 24;
	add.s64 	%rd71, %rd69, %rd70;
	st.u64 	[%rd71], %rd4;
	st.u64 	[%rd71+8], %rd112;
	add.s64 	%rd19, %rd71, 16;
	st.u32 	[%rd71+16], %r32;
	membar.sys;
	mov.u32 	%r40, 1;
	st.volatile.u32 	[%rd71+20], %r40;
	membar.sys;

BB10_21:
	ld.volatile.u32 	%r41, [%rd19+4];
	setp.ne.s32	%p16, %r41, 0;
	@%p16 bra 	BB10_21;

	ld.global.u64 	%rd72, [d_cxt+24];
	add.s64 	%rd74, %rd72, %rd67;
	atom.exch.b32 	%r42, [%rd74], 0;
	st.u64 	[%rd13+-16], %rd4;
	st.u32 	[%rd13], %r40;

BB10_29:
	atom.exch.b32 	%r54, [%rd12], 0;

BB10_30:
	mov.b64	{%r56, %r60}, %rd112;
	// inline asm
	shfl.idx.b32 %r55, %r56, %r3, %r19;
	// inline asm
	// inline asm
	shfl.idx.b32 %r59, %r60, %r3, %r19;
	// inline asm
	mov.b64	%rd26, {%r55, %r59};
	@!%p1 bra 	BB10_33;
	bra.uni 	BB10_31;

BB10_31:
	setp.eq.s64	%p19, %rd26, 0;
	mov.u16 	%rs7, 0;
	@%p19 bra 	BB10_33;

	and.b64  	%rd92, %rd113, 4095;
	and.b64  	%rd93, %rd26, 9223372036854775807;
	or.b64  	%rd113, %rd93, %rd92;

BB10_33:
	cvt.u32.u16	%r65, %rs7;
	and.b32  	%r64, %r65, 255;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r64, 0; 
	vote.ballot.b32 	%r63, %p1; 
	}
	// inline asm
	neg.s32 	%r66, %r63;
	and.b32  	%r67, %r63, %r66;
	clz.b32 	%r77, %r67;
	setp.ne.s32	%p20, %r77, 32;
	@%p20 bra 	BB10_5;

BB10_34:
	setp.lt.s64	%p21, %rd113, 0;
	@%p21 bra 	BB10_36;
	bra.uni 	BB10_35;

BB10_36:
	mov.u64 	%rd94, $str5;
	cvta.global.u64 	%rd95, %rd94;
	mov.u64 	%rd96, 0;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd95;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd96;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r69, [retval0+0];
	
	//{
	}// Callseq End 0
	and.b64  	%rd30, %rd113, 9223372036854775807;
	mov.u64 	%rd97, d_cxt;
	ld.global.u64 	%rd98, [d_cxt];
	add.s64 	%rd99, %rd98, 4294967295;
	cvt.u32.u64	%r70, %rd99;
	add.s64 	%rd100, %rd97, 16;
	atom.global.inc.u32 	%r71, [%rd100], %r70;
	cvt.s64.s32	%rd31, %r71;

BB10_37:
	ld.global.u64 	%rd101, [d_cxt+24];
	shl.b64 	%rd102, %rd31, 2;
	add.s64 	%rd103, %rd101, %rd102;
	atom.exch.b32 	%r72, [%rd103], 1;
	setp.ne.s32	%p22, %r72, 0;
	@%p22 bra 	BB10_37;

	ld.global.u64 	%rd104, [d_cxt+8];
	mul.lo.s64 	%rd105, %rd31, 24;
	add.s64 	%rd106, %rd104, %rd105;
	st.u64 	[%rd106], %rd30;
	st.u64 	[%rd106+8], %rd34;
	add.s64 	%rd32, %rd106, 16;
	mov.u32 	%r73, 4;
	st.u32 	[%rd106+16], %r73;
	membar.sys;
	mov.u32 	%r74, 1;
	st.volatile.u32 	[%rd106+20], %r74;
	membar.sys;

BB10_39:
	ld.volatile.u32 	%r75, [%rd32+4];
	setp.ne.s32	%p23, %r75, 0;
	@%p23 bra 	BB10_39;

	ld.global.u64 	%rd107, [d_cxt+24];
	add.s64 	%rd109, %rd107, %rd102;
	atom.exch.b32 	%r76, [%rd109], 0;
	bra.uni 	BB10_41;

BB10_35:
	ld.u32 	%r68, [%rd113];
	st.u32 	[%rd34], %r68;

BB10_41:
	st.param.b64	[func_retval0+0], %rd113;
	ret;
}

	// .globl	cpuptr_write_int
.visible .func  (.param .b64 func_retval0) cpuptr_write_int(
	.param .b64 cpuptr_write_int_param_0,
	.param .b32 cpuptr_write_int_param_1
)
{
	.local .align 4 .b8 	__local_depot11[4];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<24>;
	.reg .b16 	%rs<9>;
	.reg .b32 	%r<81>;
	.reg .b64 	%rd<123>;


	mov.u64 	%rd122, __local_depot11;
	cvta.local.u64 	%SP, %rd122;
	ld.param.u64 	%rd121, [cpuptr_write_int_param_0];
	ld.param.u32 	%r10, [cpuptr_write_int_param_1];
	add.u64 	%rd35, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd35;
	st.local.u32 	[%rd1], %r10;
	shr.u64 	%rd36, %rd121, 63;
	cvt.u32.u64	%r9, %rd36;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	.reg .pred 	%p2; 
	setp.ne.u32 	%p1, %r9, 0; 
	vote.any.pred 	%p2, %p1; 
	selp.s32 	%r8, 1, 0, %p2; 
	}
	// inline asm
	setp.eq.s32	%p2, %r8, 0;
	@%p2 bra 	BB11_34;

	mov.u64 	%rd118, 0;
	setp.gt.s64	%p3, %rd121, -1;
	@%p3 bra 	BB11_3;

	and.b64  	%rd118, %rd121, 9223372036854771712;

BB11_3:
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r9, 0; 
	vote.ballot.b32 	%r11, %p1; 
	}
	// inline asm
	neg.s32 	%r13, %r11;
	and.b32  	%r14, %r11, %r13;
	clz.b32 	%r80, %r14;
	setp.eq.s32	%p4, %r80, 32;
	@%p4 bra 	BB11_34;

	cvt.u16.u64	%rs8, %rd36;
	mov.b64	{%r2, %r3}, %rd118;

BB11_5:
	mov.u32 	%r4, %r80;
	mov.u32 	%r22, 31;
	sub.s32 	%r5, %r22, %r4;
	// inline asm
	shfl.idx.b32 %r15, %r2, %r5, %r22;
	// inline asm
	// inline asm
	shfl.idx.b32 %r19, %r3, %r5, %r22;
	// inline asm
	mov.b64	%rd5, {%r15, %r19};
	setp.eq.s64	%p5, %rd5, %rd118;
	and.b16  	%rs4, %rs8, 255;
	setp.ne.s16	%p6, %rs4, 0;
	and.pred  	%p1, %p6, %p5;
	selp.u32	%r24, 1, 0, %p1;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r24, 0; 
	vote.ballot.b32 	%r23, %p1; 
	}
	// inline asm
	popc.b32 	%r6, %r23;
	// inline asm
	mov.u32 %r25, %laneid;
	// inline asm
	setp.ne.s32	%p7, %r25, %r5;
	@%p7 bra 	BB11_30;

	bfe.u64 	%rd6, %rd5, 12, 51;
	ld.global.s32 	%rd7, [d_cxt+32];
	or.b64  	%rd41, %rd6, %rd7;
	and.b64  	%rd42, %rd41, -4294967296;
	setp.eq.s64	%p8, %rd42, 0;
	@%p8 bra 	BB11_8;
	bra.uni 	BB11_7;

BB11_8:
	cvt.u32.u64	%r26, %rd7;
	cvt.u32.u64	%r27, %rd6;
	rem.u32 	%r28, %r27, %r26;
	cvt.u64.u32	%rd119, %r28;
	bra.uni 	BB11_9;

BB11_7:
	rem.u64 	%rd119, %rd6, %rd7;

BB11_9:
	and.b64  	%rd11, %rd119, 4294967295;
	ld.global.u64 	%rd12, [d_cxt+48];
	mul.lo.s64 	%rd43, %rd11, 24;
	add.s64 	%rd44, %rd12, %rd43;
	add.s64 	%rd13, %rd44, 12;

BB11_10:
	atom.exch.b32 	%r29, [%rd13], 1;
	setp.ne.s32	%p9, %r29, 0;
	@%p9 bra 	BB11_10;

	add.s64 	%rd14, %rd44, 16;
	ld.u32 	%r30, [%rd44+16];
	setp.eq.s32	%p10, %r30, 0;
	@%p10 bra 	BB11_24;
	bra.uni 	BB11_12;

BB11_24:
	ld.global.u64 	%rd78, [d_cxt+40];
	shl.b64 	%rd79, %rd11, 12;
	add.s64 	%rd120, %rd78, %rd79;
	mov.u64 	%rd80, d_cxt;
	ld.global.u64 	%rd81, [d_cxt];
	add.s64 	%rd82, %rd81, 4294967295;
	cvt.u32.u64	%r49, %rd82;
	add.s64 	%rd83, %rd80, 16;
	atom.global.inc.u32 	%r50, [%rd83], %r49;
	cvt.s64.s32	%rd23, %r50;

BB11_25:
	ld.global.u64 	%rd84, [d_cxt+24];
	shl.b64 	%rd85, %rd23, 2;
	add.s64 	%rd86, %rd84, %rd85;
	atom.exch.b32 	%r51, [%rd86], 1;
	setp.ne.s32	%p17, %r51, 0;
	@%p17 bra 	BB11_25;

	ld.global.u64 	%rd87, [d_cxt+8];
	mul.lo.s64 	%rd88, %rd23, 24;
	add.s64 	%rd89, %rd87, %rd88;
	st.u64 	[%rd89], %rd5;
	st.u64 	[%rd89+8], %rd120;
	add.s64 	%rd24, %rd89, 16;
	mov.u32 	%r52, 4096;
	st.u32 	[%rd89+16], %r52;
	membar.sys;
	mov.u32 	%r53, 1;
	st.volatile.u32 	[%rd89+20], %r53;
	membar.sys;

BB11_27:
	ld.volatile.u32 	%r54, [%rd24+4];
	setp.ne.s32	%p18, %r54, 0;
	@%p18 bra 	BB11_27;

	ld.global.u64 	%rd90, [d_cxt+24];
	add.s64 	%rd92, %rd90, %rd85;
	atom.exch.b32 	%r55, [%rd92], 0;
	st.u64 	[%rd14+-16], %rd5;
	st.u32 	[%rd14+-8], %r6;
	st.u32 	[%rd14], %r53;
	bra.uni 	BB11_29;

BB11_12:
	ld.u64 	%rd15, [%rd14+-16];
	setp.eq.s64	%p11, %rd15, %rd5;
	@%p11 bra 	BB11_23;
	bra.uni 	BB11_13;

BB11_23:
	ld.global.u64 	%rd76, [d_cxt+40];
	ld.u32 	%r47, [%rd14+-8];
	add.s32 	%r48, %r47, %r6;
	st.u32 	[%rd14+-8], %r48;
	shl.b64 	%rd77, %rd11, 12;
	add.s64 	%rd120, %rd76, %rd77;
	bra.uni 	BB11_29;

BB11_13:
	ld.u32 	%r31, [%rd14+-8];
	mov.u64 	%rd120, 0;
	setp.ne.s32	%p12, %r31, 0;
	@%p12 bra 	BB11_29;

	ld.global.u64 	%rd48, [d_cxt+40];
	shl.b64 	%rd49, %rd11, 12;
	add.s64 	%rd120, %rd48, %rd49;
	mov.u64 	%rd50, d_cxt;
	ld.global.u64 	%rd51, [d_cxt];
	add.s64 	%rd52, %rd51, 4294967295;
	cvt.u32.u64	%r32, %rd52;
	add.s64 	%rd53, %rd50, 16;
	atom.global.inc.u32 	%r33, [%rd53], %r32;
	cvt.s64.s32	%rd17, %r33;

BB11_15:
	ld.global.u64 	%rd54, [d_cxt+24];
	shl.b64 	%rd55, %rd17, 2;
	add.s64 	%rd56, %rd54, %rd55;
	atom.exch.b32 	%r34, [%rd56], 1;
	setp.ne.s32	%p13, %r34, 0;
	@%p13 bra 	BB11_15;

	ld.global.u64 	%rd57, [d_cxt+8];
	mul.lo.s64 	%rd58, %rd17, 24;
	add.s64 	%rd59, %rd57, %rd58;
	st.u64 	[%rd59], %rd15;
	st.u64 	[%rd59+8], %rd120;
	add.s64 	%rd18, %rd59, 16;
	mov.u32 	%r35, 4096;
	st.u32 	[%rd59+16], %r35;
	membar.sys;
	mov.u32 	%r36, 2;
	st.volatile.u32 	[%rd59+20], %r36;
	membar.sys;

BB11_17:
	ld.volatile.u32 	%r37, [%rd18+4];
	setp.ne.s32	%p14, %r37, 0;
	@%p14 bra 	BB11_17;

	ld.global.u64 	%rd60, [d_cxt+24];
	add.s64 	%rd62, %rd60, %rd55;
	atom.exch.b32 	%r38, [%rd62], 0;
	ld.global.u64 	%rd64, [d_cxt];
	add.s64 	%rd65, %rd64, 4294967295;
	cvt.u32.u64	%r39, %rd65;
	atom.global.inc.u32 	%r40, [%rd53], %r39;
	cvt.s64.s32	%rd19, %r40;

BB11_19:
	ld.global.u64 	%rd67, [d_cxt+24];
	shl.b64 	%rd68, %rd19, 2;
	add.s64 	%rd69, %rd67, %rd68;
	atom.exch.b32 	%r41, [%rd69], 1;
	setp.ne.s32	%p15, %r41, 0;
	@%p15 bra 	BB11_19;

	ld.global.u64 	%rd70, [d_cxt+8];
	mul.lo.s64 	%rd71, %rd19, 24;
	add.s64 	%rd72, %rd70, %rd71;
	st.u64 	[%rd72], %rd5;
	st.u64 	[%rd72+8], %rd120;
	add.s64 	%rd20, %rd72, 16;
	st.u32 	[%rd72+16], %r35;
	membar.sys;
	mov.u32 	%r43, 1;
	st.volatile.u32 	[%rd72+20], %r43;
	membar.sys;

BB11_21:
	ld.volatile.u32 	%r44, [%rd20+4];
	setp.ne.s32	%p16, %r44, 0;
	@%p16 bra 	BB11_21;

	ld.global.u64 	%rd73, [d_cxt+24];
	add.s64 	%rd75, %rd73, %rd68;
	atom.exch.b32 	%r45, [%rd75], 0;
	st.u64 	[%rd14+-16], %rd5;
	st.u32 	[%rd14], %r43;

BB11_29:
	atom.exch.b32 	%r57, [%rd13], 0;

BB11_30:
	mov.b64	{%r59, %r63}, %rd120;
	// inline asm
	shfl.idx.b32 %r58, %r59, %r5, %r22;
	// inline asm
	// inline asm
	shfl.idx.b32 %r62, %r63, %r5, %r22;
	// inline asm
	mov.b64	%rd27, {%r58, %r62};
	@!%p1 bra 	BB11_33;
	bra.uni 	BB11_31;

BB11_31:
	setp.eq.s64	%p19, %rd27, 0;
	mov.u16 	%rs8, 0;
	@%p19 bra 	BB11_33;

	and.b64  	%rd93, %rd121, 4095;
	and.b64  	%rd94, %rd27, 9223372036854775807;
	or.b64  	%rd121, %rd94, %rd93;

BB11_33:
	cvt.u32.u16	%r68, %rs8;
	and.b32  	%r67, %r68, 255;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r67, 0; 
	vote.ballot.b32 	%r66, %p1; 
	}
	// inline asm
	neg.s32 	%r69, %r66;
	and.b32  	%r70, %r66, %r69;
	clz.b32 	%r80, %r70;
	setp.ne.s32	%p20, %r80, 32;
	@%p20 bra 	BB11_5;

BB11_34:
	setp.lt.s64	%p21, %rd121, 0;
	@%p21 bra 	BB11_36;
	bra.uni 	BB11_35;

BB11_36:
	mov.u64 	%rd101, $str6;
	cvta.global.u64 	%rd102, %rd101;
	mov.u64 	%rd103, 0;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd102;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd103;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r72, [retval0+0];
	
	//{
	}// Callseq End 1
	and.b64  	%rd31, %rd121, 9223372036854775807;
	mov.u64 	%rd104, d_cxt;
	ld.global.u64 	%rd105, [d_cxt];
	add.s64 	%rd106, %rd105, 4294967295;
	cvt.u32.u64	%r73, %rd106;
	add.s64 	%rd107, %rd104, 16;
	atom.global.inc.u32 	%r74, [%rd107], %r73;
	cvt.s64.s32	%rd32, %r74;

BB11_37:
	ld.global.u64 	%rd108, [d_cxt+24];
	shl.b64 	%rd109, %rd32, 2;
	add.s64 	%rd110, %rd108, %rd109;
	atom.exch.b32 	%r75, [%rd110], 1;
	setp.ne.s32	%p22, %r75, 0;
	@%p22 bra 	BB11_37;

	ld.global.u64 	%rd111, [d_cxt+8];
	mul.lo.s64 	%rd112, %rd32, 24;
	add.s64 	%rd113, %rd111, %rd112;
	st.u64 	[%rd113], %rd31;
	st.u64 	[%rd113+8], %rd35;
	add.s64 	%rd33, %rd113, 16;
	mov.u32 	%r76, 4;
	st.u32 	[%rd113+16], %r76;
	membar.sys;
	mov.u32 	%r77, 2;
	st.volatile.u32 	[%rd113+20], %r77;
	membar.sys;

BB11_39:
	ld.volatile.u32 	%r78, [%rd33+4];
	setp.ne.s32	%p23, %r78, 0;
	@%p23 bra 	BB11_39;

	ld.global.u64 	%rd115, [d_cxt+24];
	add.s64 	%rd117, %rd115, %rd109;
	atom.exch.b32 	%r79, [%rd117], 0;
	bra.uni 	BB11_41;

BB11_35:
	ld.global.u64 	%rd95, [d_cxt+40];
	sub.s64 	%rd96, %rd121, %rd95;
	ld.local.u32 	%r71, [%rd1];
	st.u32 	[%rd121], %r71;
	bfe.s64 	%rd97, %rd96, 12, 32;
	ld.global.u64 	%rd98, [d_cxt+48];
	mul.lo.s64 	%rd99, %rd97, 24;
	add.s64 	%rd100, %rd98, %rd99;
	mov.u16 	%rs7, 1;
	st.u8 	[%rd100+20], %rs7;
	membar.gl;

BB11_41:
	st.param.b64	[func_retval0+0], %rd121;
	ret;
}

	// .globl	cpuptr_inc
.visible .func  (.param .b64 func_retval0) cpuptr_inc(
	.param .b64 cpuptr_inc_param_0,
	.param .b32 cpuptr_inc_param_1
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<29>;


	ld.param.u64 	%rd12, [cpuptr_inc_param_0];
	ld.param.u32 	%r4, [cpuptr_inc_param_1];
	cvt.s64.s32	%rd1, %r4;
	setp.lt.s32	%p1, %r4, 0;
	@%p1 bra 	BB12_2;

	and.b64  	%rd13, %rd12, 4095;
	add.s64 	%rd14, %rd13, %rd1;
	setp.lt.u64	%p2, %rd14, 4096;
	@%p2 bra 	BB12_9;

BB12_2:
	setp.lt.s64	%p3, %rd12, 0;
	@%p3 bra 	BB12_9;

	ld.global.u64 	%rd15, [d_cxt+40];
	sub.s64 	%rd3, %rd12, %rd15;
	bfe.s64 	%rd16, %rd3, 12, 32;
	ld.global.u64 	%rd4, [d_cxt+48];
	mul.lo.s64 	%rd17, %rd16, 24;
	add.s64 	%rd18, %rd4, %rd17;
	ld.u64 	%rd19, [%rd18];
	and.b64  	%rd20, %rd12, 4095;
	or.b64  	%rd21, %rd19, %rd20;
	add.s64 	%rd5, %rd21, %rd1;
	and.b64  	%rd22, %rd5, 9223372036854771712;
	setp.eq.s64	%p4, %rd19, %rd22;
	@%p4 bra 	BB12_9;

	and.b64  	%rd23, %rd3, 17592186040320;
	bfe.u64 	%rd24, %rd3, 12, 32;
	cvt.u32.u64	%r1, %rd24;
	bfe.s64 	%rd6, %rd23, 12, 32;
	mov.u32 	%r22, 0;
	mov.u16 	%rs5, 1;

BB12_5:
	cvt.u32.u16	%r15, %rs5;
	cvt.s32.s8 	%r7, %r15;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r7, 0; 
	vote.ballot.b32 	%r6, %p1; 
	}
	// inline asm
	neg.s32 	%r16, %r6;
	and.b32  	%r17, %r6, %r16;
	clz.b32 	%r18, %r17;
	mov.u32 	%r11, 31;
	sub.s32 	%r10, %r11, %r18;
	// inline asm
	shfl.idx.b32 %r8, %r1, %r10, %r11;
	// inline asm
	setp.eq.s32	%p5, %r1, %r8;
	selp.u32	%r13, 1, 0, %p5;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r13, 0; 
	vote.ballot.b32 	%r12, %p1; 
	}
	// inline asm
	popc.b32 	%r19, %r12;
	// inline asm
	mov.u32 %r14, %laneid;
	// inline asm
	setp.eq.s32	%p6, %r10, %r14;
	selp.b32	%r22, %r19, %r22, %p6;
	selp.b16	%rs5, 0, %rs5, %p5;
	and.b16  	%rs4, %rs5, 255;
	setp.ne.s16	%p7, %rs4, 0;
	@%p7 bra 	BB12_5;

	setp.eq.s32	%p8, %r22, 0;
	@%p8 bra 	BB12_8;

	mul.lo.s64 	%rd25, %rd6, 24;
	add.s64 	%rd26, %rd4, %rd25;
	add.s64 	%rd27, %rd26, 8;
	neg.s32 	%r20, %r22;
	atom.add.u32 	%r21, [%rd27], %r20;

BB12_8:
	or.b64  	%rd28, %rd5, -9223372036854775808;
	bra.uni 	BB12_10;

BB12_9:
	add.s64 	%rd28, %rd1, %rd12;

BB12_10:
	st.param.b64	[func_retval0+0], %rd28;
	ret;
}

	// .globl	cpuptr_release
.visible .func cpuptr_release(
	.param .b64 cpuptr_release_param_0
)
{
	.reg .pred 	%p<9>;
	.reg .b16 	%rs<6>;
	.reg .b32 	%r<24>;
	.reg .b64 	%rd<11>;


	ld.param.u64 	%rd3, [cpuptr_release_param_0];
	setp.gt.s64	%p1, %rd3, -1;
	selp.u32	%r5, 1, 0, %p1;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	.reg .pred 	%p2; 
	setp.ne.u32 	%p1, %r5, 0; 
	vote.any.pred 	%p2, %p1; 
	selp.s32 	%r4, 1, 0, %p2; 
	}
	// inline asm
	setp.eq.s32	%p2, %r4, 0;
	setp.lt.s64	%p3, %rd3, 0;
	or.pred  	%p4, %p2, %p3;
	@%p4 bra 	BB13_5;

	ld.global.u64 	%rd4, [d_cxt+40];
	sub.s64 	%rd5, %rd3, %rd4;
	and.b64  	%rd6, %rd5, 17592186040320;
	bfe.u64 	%rd7, %rd5, 12, 32;
	cvt.u32.u64	%r1, %rd7;
	ld.global.u64 	%rd1, [d_cxt+48];
	bfe.s64 	%rd2, %rd6, 12, 32;
	mov.u32 	%r23, 0;
	mov.u16 	%rs5, 1;

BB13_2:
	cvt.u32.u16	%r16, %rs5;
	cvt.s32.s8 	%r8, %r16;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r8, 0; 
	vote.ballot.b32 	%r7, %p1; 
	}
	// inline asm
	neg.s32 	%r17, %r7;
	and.b32  	%r18, %r7, %r17;
	clz.b32 	%r19, %r18;
	mov.u32 	%r12, 31;
	sub.s32 	%r11, %r12, %r19;
	// inline asm
	shfl.idx.b32 %r9, %r1, %r11, %r12;
	// inline asm
	setp.eq.s32	%p5, %r1, %r9;
	selp.u32	%r14, 1, 0, %p5;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	setp.ne.u32 	%p1, %r14, 0; 
	vote.ballot.b32 	%r13, %p1; 
	}
	// inline asm
	popc.b32 	%r20, %r13;
	// inline asm
	mov.u32 %r15, %laneid;
	// inline asm
	setp.eq.s32	%p6, %r11, %r15;
	selp.b32	%r23, %r20, %r23, %p6;
	selp.b16	%rs5, 0, %rs5, %p5;
	and.b16  	%rs4, %rs5, 255;
	setp.ne.s16	%p7, %rs4, 0;
	@%p7 bra 	BB13_2;

	setp.eq.s32	%p8, %r23, 0;
	@%p8 bra 	BB13_5;

	mul.lo.s64 	%rd8, %rd2, 24;
	add.s64 	%rd9, %rd1, %rd8;
	add.s64 	%rd10, %rd9, 8;
	neg.s32 	%r21, %r23;
	atom.add.u32 	%r22, [%rd10], %r21;

BB13_5:
	ret;
}


